{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>**Exploring SpaCy**</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. Spacy is really good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing SpaCy \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(u'Trying to understand what Spacy does and exploring its different features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>**Tokenization**</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying\n",
      "to\n",
      "understand\n",
      "what\n",
      "Spacy\n",
      "does\n",
      "and\n",
      "exploring\n",
      "its\n",
      "different\n",
      "features\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the raw text is split on whitespace characters, similar to text.split(' '). Then, the tokenizer processes the text from left to right. On each substring, it performs two checks:\n",
    "\n",
    "1. **Does the substring match a tokenizer exception rule?** For example, \"don't\" does not contain whitespace, but should be split into two tokens, \"do\" and \"n't\".\n",
    "2. **Can a prefix, suffix or infix be split off?** For example punctuation like commas, periods, hyphens or quotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>**Part-of-speech tags and dependencies**</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying try VERB VBG ROOT Xxxxx True False\n",
      "\n",
      "to to PART TO aux xx True True\n",
      "\n",
      "understand understand VERB VB xcomp xxxx True False\n",
      "\n",
      "what what NOUN WP dobj xxxx True True\n",
      "\n",
      "Spacy spacy PROPN NNP nsubj Xxxxx True False\n",
      "\n",
      "does do VERB VBZ ccomp xxxx True True\n",
      "\n",
      "and and CCONJ CC cc xxx True True\n",
      "\n",
      "exploring explore VERB VBG conj xxxx True False\n",
      "\n",
      "its -PRON- ADJ PRP$ poss xxx True True\n",
      "\n",
      "different different ADJ JJ amod xxxx True False\n",
      "\n",
      "features feature NOUN NNS dobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Trying to understand what Spacy does and exploring its different features')\n",
    "\n",
    "for token in doc:\n",
    "    print()\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**[column 1] Text: The original word text.**\n",
    "\n",
    "**[column 2] Lemma: The base form of the word.**\n",
    "\n",
    "**[column 3] POS: The simple part-of-speech tag.**\n",
    "\n",
    "**[column 4] Tag: The detailed part-of-speech tag.**\n",
    "\n",
    "**[column 5] Dep: Syntactic dependency, i.e. the relation between tokens.**\n",
    "\n",
    "**[column 6] Shape: The word shape â€“ capitalisation, punctuation, digits.**\n",
    "\n",
    "**[column 7] is alpha: Is the token an alpha character?**\n",
    "\n",
    "**[column 8] is stop: Is the token part of a stop list, i.e. the most common words of the language?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>**Named Entities**</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy 26 31 GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Trying to understand what Spacy does and exploring its different features')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[column 1] Text: The original entity text.**\n",
    "\n",
    "**[column 2] Start: Index of start of entity in the Doc.**\n",
    "    \n",
    "**[column 3] End: Index of end of entity in the Doc.**\n",
    "    \n",
    "**[column 4] Label: Entity label, i.e. type.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>**Word vectors and similarity**</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  \t\n",
      "0.659165  \t\n",
      "0.458621  \t\n",
      "0.659165  \t\n",
      "1.0  \t\n",
      "0.663724  \t\n",
      "0.458621  \t\n",
      "0.663724  \t\n",
      "1.0  \t\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'bus car man')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.similarity(token2),\" \\t\")\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
